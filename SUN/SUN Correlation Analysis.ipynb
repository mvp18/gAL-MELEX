{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_list=[]\n",
    "image_names = io.loadmat('images.mat')['images']\n",
    "image_attributes = io.loadmat('attributeLabels_continuous.mat')['labels_cv']\n",
    "for i in range(image_names.shape[0]):\n",
    "    img_list.append(image_names[i][0][0])\n",
    "att_dict = dict(zip(img_list, image_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res101 = io.loadmat('../../resnet-feats/SUN/res101.mat')\n",
    "att_splits = io.loadmat('att_splits.mat')\n",
    "train_loc = 'train_loc'\n",
    "val_loc = 'val_loc'\n",
    "test_loc = 'test_unseen_loc'\n",
    "train_images = res101['image_files'][np.squeeze(att_splits[train_loc]-1)]\n",
    "val_images = res101['image_files'][np.squeeze(att_splits[val_loc]-1)]\n",
    "test_images = res101['image_files'][np.squeeze(att_splits[test_loc]-1)]\n",
    "class_labels = res101['labels']\n",
    "prior_matrix = att_splits['att']\n",
    "test_classes = class_labels[np.squeeze(att_splits[test_loc]-1)]\n",
    "prior_matrix_ts = prior_matrix[:,(np.unique(test_classes)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images = 11600\n",
      "Val images = 1300\n",
      "Test images = 1440\n"
     ]
    }
   ],
   "source": [
    "print 'Train images = ' + str(len(train_images)) + '\\nVal images = ' + str(len(val_images)) + '\\nTest images = ' + str(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_att=np.zeros([train_images.shape[0], image_attributes.shape[1]])\n",
    "for i in range(train_images.shape[0]):\n",
    "    img_name=train_images[i][0][0].split('images/')[1]\n",
    "    train_att[i] = np.round(att_dict[img_name])\n",
    "val_att=np.zeros([val_images.shape[0], image_attributes.shape[1]])\n",
    "for i in range(val_images.shape[0]):\n",
    "    img_name=val_images[i][0][0].split('images/')[1]\n",
    "    val_att[i] = np.round(att_dict[img_name])\n",
    "test_att=np.zeros([test_images.shape[0], image_attributes.shape[1]])\n",
    "for i in range(test_images.shape[0]):\n",
    "    img_name=test_images[i][0][0].split('images/')[1]\n",
    "    test_att[i] = np.round(att_dict[img_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_train = np.corrcoef(train_att.transpose())\n",
    "nans = np.isnan(corr_train)\n",
    "corr_train[nans] = 0\n",
    "corr_test = np.corrcoef(prior_matrix_ts)\n",
    "nans = np.isnan(corr_test)\n",
    "corr_test[nans] = 0\n",
    "def diff_corr(corr_train, corr_test):\n",
    "    dis_corr = (corr_train - corr_test)\n",
    "    dis_corr = np.sign(corr_train)*dis_corr\n",
    "    return dis_corr.clip(0,np.inf)\n",
    "dis_corr = diff_corr(corr_train, corr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55039062, 0.55039062, 0.41646005, 0.41646005, 0.41448207,\n",
       "       0.41448207, 0.40933447, 0.40933447, 0.3882846 , 0.3882846 ,\n",
       "       0.38106693, 0.38106693, 0.36520544, 0.36520544, 0.35411016,\n",
       "       0.35411016, 0.35328142, 0.35328142, 0.3480737 , 0.3480737 ,\n",
       "       0.34444056, 0.34444056, 0.33448378, 0.33448378, 0.33150595,\n",
       "       0.33150595, 0.33143327, 0.33143327, 0.31892079, 0.31892079,\n",
       "       0.3174054 , 0.3174054 , 0.31633169, 0.31633169, 0.31623479,\n",
       "       0.31623479, 0.30111212, 0.30111212, 0.29919132, 0.29919132,\n",
       "       0.29809287, 0.29809287, 0.29499453, 0.29499453, 0.29404743,\n",
       "       0.29404743, 0.287901  , 0.287901  , 0.28564063, 0.28564063,\n",
       "       0.28428015, 0.28428015, 0.28398512, 0.28398512, 0.28386863,\n",
       "       0.28386863, 0.27735522, 0.27735522, 0.27047488, 0.27047488,\n",
       "       0.26675528, 0.26675528, 0.26634216, 0.26634216, 0.26162947,\n",
       "       0.26162947, 0.26094019, 0.26094019, 0.26090891, 0.26090891,\n",
       "       0.25988597, 0.25988597, 0.25717829, 0.25717829, 0.25517655,\n",
       "       0.25517655, 0.25440224, 0.25440224, 0.2492926 , 0.2492926 ,\n",
       "       0.24653396, 0.24653396, 0.2458534 , 0.2458534 , 0.23935714,\n",
       "       0.23935714, 0.23752477, 0.23752477, 0.23485919, 0.23485919,\n",
       "       0.23376611, 0.23376611, 0.23324528, 0.23324528, 0.23299932,\n",
       "       0.23299932, 0.23135758, 0.23135758, 0.22711993, 0.22711993])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = np.unravel_index(np.argsort(-dis_corr, axis=None)[:100], dis_corr.shape)\n",
    "dis_corr[loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015219056458505086"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "### New split for SUN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([u'/BS/Deep_Fragments/work/MSc/data/SUN/images/a/abbey/sun_aakbdcgfpksytcwj.jpg'],\n",
       "      dtype='<U76')],\n",
       "       [array([u'/BS/Deep_Fragments/work/MSc/data/SUN/images/a/abbey/sun_aaoktempcmudsvna.jpg'],\n",
       "      dtype='<U76')],\n",
       "       [array([u'/BS/Deep_Fragments/work/MSc/data/SUN/images/a/abbey/sun_abegcweqnetpdlrh.jpg'],\n",
       "      dtype='<U76')],\n",
       "       ...,\n",
       "       [array([u'/BS/Deep_Fragments/work/MSc/data/SUN/images/z/zoo/sun_bvyaxgkxlaeedguu.jpg'],\n",
       "      dtype='<U74')],\n",
       "       [array([u'/BS/Deep_Fragments/work/MSc/data/SUN/images/z/zoo/sun_bxjkxzvljdwtnjud.jpg'],\n",
       "      dtype='<U74')],\n",
       "       [array([u'/BS/Deep_Fragments/work/MSc/data/SUN/images/z/zoo/sun_bxydkwwiknutjnun.jpg'],\n",
       "      dtype='<U74')]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res101['image_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img = att_dict.keys()\n",
    "cls = [img.split('/')[1] for img in all_img]\n",
    "len(np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1],\n",
       "       [  1],\n",
       "       [  1],\n",
       "       ...,\n",
       "       [717],\n",
       "       [717],\n",
       "       [717]], dtype=uint16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res101['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_splits = io.loadmat('att_splits.mat') #ZSL_GBU data\n",
    "image_names = np.array([x[0][0].split('images/')[1] for x in res101['image_files']])\n",
    "class_labels = res101['labels']\n",
    "name2class = dict(zip(image_names, np.squeeze(class_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2name = {}\n",
    "for n in name2class:\n",
    "    c = name2class[n]\n",
    "    if c not in class2name:\n",
    "        class2name[c] = [n]\n",
    "    else:\n",
    "        class2name[c].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_corr(corr_train, corr_test):\n",
    "    dis_corr = (corr_train - corr_test)\n",
    "    dis_corr = np.sign(corr_train)*dis_corr\n",
    "    return dis_corr.clip(0,np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corr_shift(att_dict, class2name, train_class, test_class):\n",
    "    test_att_mat = []\n",
    "    train_att_mat = []\n",
    "    for cls in train_class:\n",
    "        for img in class2name[cls]:\n",
    "            train_att_mat.append(att_dict[img])\n",
    "    for cls in test_class:\n",
    "        for img in class2name[cls]:\n",
    "            test_att_mat.append(att_dict[img])\n",
    "#     print '#Train instances = ' + str(len(train_att_mat)) + '\\n#Test instances = ' + str(len(test_att_mat))\n",
    "    \n",
    "    train_att_mat = np.array(train_att_mat).transpose()\n",
    "    test_att_mat = np.array(test_att_mat).transpose()\n",
    "    \n",
    "    corr_train = np.corrcoef(train_att_mat)\n",
    "    corr_train[np.isnan(corr_train)] = 0.\n",
    "    corr_test = np.corrcoef(test_att_mat)\n",
    "    corr_test[np.isnan(corr_test)] = 0.\n",
    "    \n",
    "    dis_corr = diff_corr(corr_train, corr_test)\n",
    "    \n",
    "    # correlation shift score: \n",
    "    # 1) mean\n",
    "    # corr_shift_score = np.mean(dis_corr)\n",
    "    \n",
    "    # 2) average of top n%\n",
    "    dis_corr_array = dis_corr.flatten()\n",
    "    top_percentage = 100\n",
    "    num_elements = int((top_percentage/100.)*len(dis_corr_array))\n",
    "    corr_shift_score = np.mean(dis_corr_array[np.argsort(dis_corr_array)[-num_elements:]])\n",
    "    \n",
    "    return corr_shift_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = np.unique([name2class['/'.join(tr[0][0].split('/')[8:])] for tr in train_images])\n",
    "val_classes = np.unique([name2class['/'.join(val[0][0].split('/')[8:])] for val in val_images])\n",
    "test_classes = np.unique([name2class['/'.join(te[0][0].split('/')[8:])] for te in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03247590150450682"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_corr_shift(att_dict, class2name, train_classes, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 20 -> 0.20462419926437994 :18.3212909698s\n",
      "2) 141 -> 0.2093474935863399 :36.9060668945s\n",
      "3) 583 -> 0.20047480836126033 :56.3604898453s\n",
      "4) 662 -> 0.19322437318073618 :73.2223098278s\n",
      "5) 663 -> 0.18833242156442223 :92.0463619232s\n",
      "6) 660 -> 0.1837130609114906 :110.226444006s\n",
      "7) 388 -> 0.1802782199504697 :129.345793009s\n",
      "8) 664 -> 0.17829927410810625 :149.48506999s\n",
      "9) 661 -> 0.17622179441352848 :169.875679016s\n",
      "10) 666 -> 0.17429209823472316 :188.391891003s\n",
      "11) 609 -> 0.17174128692156115 :207.412191868s\n",
      "12) 145 -> 0.16907402098510294 :225.539800882s\n",
      "13) 156 -> 0.16604607730706417 :243.031993866s\n",
      "14) 455 -> 0.1634614413357417 :261.67262888s\n",
      "15) 460 -> 0.16136732161467804 :279.927438021s\n",
      "16) 486 -> 0.15907406963691845 :299.908885002s\n",
      "17) 94 -> 0.15716594599212874 :318.51018095s\n",
      "18) 193 -> 0.15553520096515455 :335.962906837s\n",
      "19) 414 -> 0.15411966550812403 :353.242909908s\n",
      "20) 615 -> 0.15254917703328633 :372.411615849s\n",
      "21) 535 -> 0.1519518071301455 :389.708205938s\n",
      "22) 552 -> 0.15070018122676382 :408.858501911s\n",
      "23) 379 -> 0.1499865977227534 :431.25242281s\n",
      "24) 52 -> 0.1487588123409769 :449.518332958s\n",
      "25) 355 -> 0.14765011237903833 :468.637346983s\n",
      "26) 673 -> 0.1466172561072345 :487.223641872s\n",
      "27) 112 -> 0.14582633372000822 :505.92610693s\n",
      "28) 36 -> 0.1449008596791561 :523.749419928s\n",
      "29) 674 -> 0.1440836628613993 :541.407087803s\n",
      "30) 438 -> 0.14314702393280285 :559.822089911s\n",
      "31) 318 -> 0.14220538039755481 :578.394204855s\n",
      "32) 119 -> 0.14125285482280225 :598.054668903s\n",
      "33) 307 -> 0.14035755854353357 :618.177596807s\n",
      "34) 154 -> 0.1395376377135495 :635.326699018s\n",
      "35) 258 -> 0.13863817730848743 :654.228767872s\n",
      "36) 348 -> 0.13777158571537737 :672.673973799s\n",
      "37) 614 -> 0.13698369464610588 :689.955814838s\n",
      "38) 665 -> 0.13647729098544611 :709.815603018s\n",
      "39) 292 -> 0.1357944381184984 :729.724856853s\n",
      "40) 14 -> 0.13514243527107667 :747.78211689s\n",
      "41) 580 -> 0.13456586062261497 :766.140393019s\n",
      "42) 581 -> 0.13412771906961654 :784.596393824s\n",
      "43) 347 -> 0.13370059384756794 :803.64388299s\n",
      "44) 195 -> 0.13315630781179005 :822.753786802s\n",
      "45) 520 -> 0.1326543908558324 :842.413699865s\n",
      "46) 415 -> 0.13222954752971755 :863.686564922s\n",
      "47) 585 -> 0.13183141445327656 :883.897001982s\n",
      "48) 476 -> 0.13139389110252536 :903.232925892s\n",
      "49) 23 -> 0.13107763918912566 :921.900249958s\n",
      "50) 362 -> 0.1306890687803099 :941.713186979s\n",
      "51) 363 -> 0.13035473861912977 :961.278983831s\n",
      "52) 582 -> 0.12999275345731323 :978.680159807s\n",
      "53) 579 -> 0.1297255576739692 :996.631824017s\n",
      "54) 227 -> 0.12939030550596411 :1016.867028s\n",
      "55) 163 -> 0.12906350475859077 :1033.83391881s\n",
      "56) 559 -> 0.12877875349309406 :1053.198452s\n",
      "57) 505 -> 0.12846322374820285 :1074.71728301s\n",
      "58) 179 -> 0.12818681766083642 :1093.56810999s\n",
      "59) 532 -> 0.12806082647163994 :1111.47461891s\n",
      "60) 572 -> 0.1278442591382658 :1130.70899892s\n",
      "61) 548 -> 0.12760881122022352 :1149.50367093s\n",
      "62) 246 -> 0.1274188045588027 :1169.81371999s\n",
      "63) 152 -> 0.1272539264205753 :1186.43982387s\n",
      "64) 702 -> 0.12714700339798019 :1203.05455589s\n",
      "65) 454 -> 0.12699453426864457 :1219.582793s\n",
      "66) 599 -> 0.12681107994653082 :1238.78178501s\n",
      "67) 401 -> 0.12668202550059554 :1259.60398388s\n",
      "68) 380 -> 0.126757299074712 :1278.51816082s\n",
      "69) 330 -> 0.12671514882854937 :1297.24143481s\n",
      "70) 108 -> 0.12663638107398384 :1315.92929196s\n",
      "71) 249 -> 0.12660661050339625 :1333.99572992s\n",
      "72) 443 -> 0.12657631504353678 :1352.69470286s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "selected_classes = []\n",
    "remaining_classes = range(718)\n",
    "remaining_classes.remove(0)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(72):\n",
    "    best_cls = ''\n",
    "    best_score = -1.\n",
    "    for cls in remaining_classes:\n",
    "        new_sel = selected_classes[:]\n",
    "        new_sel.append(cls)\n",
    "        new_rem = remaining_classes[:]\n",
    "        new_rem.remove(cls)\n",
    "        shift_score = get_corr_shift(att_dict, class2name, new_rem, new_sel)\n",
    "        if shift_score > best_score:\n",
    "            best_score = shift_score\n",
    "            best_cls = cls\n",
    "    selected_classes.append(best_cls)\n",
    "    remaining_classes.remove(best_cls)\n",
    "    print str(i+1) + ') ' + str(selected_classes[-1]) + ' -> ' + str(best_score) + ' :' + str(time.time() - start_time)+ 's' \n",
    "\n",
    "test_set = selected_classes[:]\n",
    "train_val = remaining_classes[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes = range(718)\n",
    "all_classes.remove(0)\n",
    "train_val = all_classes[:]\n",
    "for cls in all_classes:\n",
    "    if cls in test_set:\n",
    "        train_val.remove(cls) \n",
    "len(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 354 -> 0.1269732853018949\n",
      "2) 345 -> 0.12722343007394799\n",
      "3) 538 -> 0.12740130037072006\n",
      "4) 283 -> 0.1276036353217557\n",
      "5) 271 -> 0.12783243105137734\n",
      "6) 477 -> 0.12802720410429658\n",
      "7) 219 -> 0.12822483603226514\n",
      "8) 655 -> 0.12841089436826603\n",
      "9) 82 -> 0.12859504961985427\n",
      "10) 508 -> 0.1287134120009919\n",
      "11) 270 -> 0.12883888644085156\n",
      "12) 334 -> 0.12899817623008233\n",
      "13) 333 -> 0.12913922529884012\n",
      "14) 416 -> 0.12926684676178427\n",
      "15) 494 -> 0.1294062882700574\n",
      "16) 53 -> 0.1295847677916621\n",
      "17) 261 -> 0.1297270759993281\n",
      "18) 516 -> 0.12987119027626\n",
      "19) 233 -> 0.13003370154504618\n",
      "20) 604 -> 0.13028866986827206\n",
      "21) 697 -> 0.13044779282426364\n",
      "22) 253 -> 0.13059373657837528\n",
      "23) 254 -> 0.13073933173013058\n",
      "24) 690 -> 0.13087716503395916\n",
      "25) 308 -> 0.13099731578571006\n",
      "26) 296 -> 0.13111697699816074\n",
      "27) 502 -> 0.13124521639087916\n",
      "28) 596 -> 0.1313744891650859\n",
      "29) 554 -> 0.13150024274430447\n",
      "30) 120 -> 0.1316546848234275\n",
      "31) 162 -> 0.1317680650012808\n",
      "32) 349 -> 0.13192344779564108\n",
      "33) 524 -> 0.13202762130807577\n",
      "34) 323 -> 0.1321317944865634\n",
      "35) 370 -> 0.13224370651078637\n",
      "36) 87 -> 0.132346231760096\n",
      "37) 42 -> 0.1324562846175756\n",
      "38) 628 -> 0.1325775755582808\n",
      "39) 540 -> 0.13268002833427747\n",
      "40) 17 -> 0.13277936059308756\n",
      "41) 468 -> 0.13287812076830469\n",
      "42) 111 -> 0.1329926917295272\n",
      "43) 336 -> 0.13311943025751624\n",
      "44) 76 -> 0.1332389603028809\n",
      "45) 286 -> 0.13348090258133127\n",
      "46) 570 -> 0.1335959081386135\n",
      "47) 289 -> 0.13371001453194428\n",
      "48) 64 -> 0.1337977555403638\n",
      "49) 393 -> 0.13388244194902166\n",
      "50) 705 -> 0.13398145914380363\n",
      "51) 294 -> 0.1340928520093043\n",
      "52) 703 -> 0.13420289692165277\n",
      "53) 105 -> 0.1342983750788611\n",
      "54) 235 -> 0.13441103334505378\n",
      "55) 688 -> 0.13453926153318066\n",
      "56) 123 -> 0.13465557231357517\n",
      "57) 51 -> 0.13478584497626522\n",
      "58) 106 -> 0.1348889300047058\n",
      "59) 29 -> 0.13501171370840612\n",
      "60) 543 -> 0.13511169059776268\n",
      "61) 3 -> 0.13522414003097077\n",
      "62) 462 -> 0.13532425152327388\n",
      "63) 155 -> 0.135416859846578\n",
      "64) 115 -> 0.13550991096956375\n",
      "65) 519 -> 0.13562266256141875\n"
     ]
    }
   ],
   "source": [
    "selected_classes = []\n",
    "remaining_classes = train_val[:]\n",
    "for i in range(65):\n",
    "    best_cls = ''\n",
    "    best_score = -1.\n",
    "    for cls in remaining_classes:\n",
    "        new_sel = selected_classes[:]\n",
    "        new_sel.append(cls)\n",
    "        new_rem = remaining_classes[:]\n",
    "        new_rem.remove(cls)\n",
    "        shift_score = get_corr_shift(att_dict, class2name, new_rem, test_set)\n",
    "        if shift_score > best_score:\n",
    "            best_score = shift_score\n",
    "            best_cls = cls\n",
    "    selected_classes.append(best_cls)\n",
    "    remaining_classes.remove(best_cls)\n",
    "    print str(i+1) + ') ' + str(selected_classes[-1]) + ' -> ' + str(best_score)\n",
    "train_set = remaining_classes[:]\n",
    "val_set = selected_classes[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03247590150450682\n",
      "0.13562266256141875\n"
     ]
    }
   ],
   "source": [
    "print get_corr_shift(att_dict, class2name, train_classes, test_classes)\n",
    "print get_corr_shift(att_dict, class2name, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016239680487793468\n",
      "0.07378322213034062\n"
     ]
    }
   ],
   "source": [
    "print get_corr_shift(att_dict, class2name, train_classes, test_classes)\n",
    "print get_corr_shift(att_dict, class2name, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = 0\n",
    "for cls in test_set:\n",
    "    test_count += len(class2name[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_dict = {}\n",
    "split_dict['train_cls'] = train_set\n",
    "split_dict['val_cls'] = val_set\n",
    "split_dict['test_cls'] = test_set\n",
    "\n",
    "import pickle\n",
    "with open('sun_cs_split.npy', 'wb') as fp:\n",
    "    np.save(fp, split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_cls': [20,\n",
       "  141,\n",
       "  583,\n",
       "  662,\n",
       "  663,\n",
       "  660,\n",
       "  388,\n",
       "  664,\n",
       "  661,\n",
       "  666,\n",
       "  609,\n",
       "  145,\n",
       "  156,\n",
       "  455,\n",
       "  460,\n",
       "  486,\n",
       "  94,\n",
       "  193,\n",
       "  414,\n",
       "  615,\n",
       "  535,\n",
       "  552,\n",
       "  379,\n",
       "  52,\n",
       "  355,\n",
       "  673,\n",
       "  112,\n",
       "  36,\n",
       "  674,\n",
       "  438,\n",
       "  318,\n",
       "  119,\n",
       "  307,\n",
       "  154,\n",
       "  258,\n",
       "  348,\n",
       "  614,\n",
       "  665,\n",
       "  292,\n",
       "  14,\n",
       "  580,\n",
       "  581,\n",
       "  347,\n",
       "  195,\n",
       "  520,\n",
       "  415,\n",
       "  585,\n",
       "  476,\n",
       "  23,\n",
       "  362,\n",
       "  363,\n",
       "  582,\n",
       "  579,\n",
       "  227,\n",
       "  163,\n",
       "  559,\n",
       "  505,\n",
       "  179,\n",
       "  532,\n",
       "  572,\n",
       "  548,\n",
       "  246,\n",
       "  152,\n",
       "  702,\n",
       "  454,\n",
       "  599,\n",
       "  401,\n",
       "  380,\n",
       "  330,\n",
       "  108,\n",
       "  249,\n",
       "  443],\n",
       " 'train_cls': [1,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  15,\n",
       "  16,\n",
       "  18,\n",
       "  19,\n",
       "  21,\n",
       "  22,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  107,\n",
       "  109,\n",
       "  110,\n",
       "  113,\n",
       "  114,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  121,\n",
       "  122,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  153,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  180,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  194,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  216,\n",
       "  217,\n",
       "  218,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  223,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  234,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  247,\n",
       "  248,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  259,\n",
       "  260,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  266,\n",
       "  267,\n",
       "  268,\n",
       "  269,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  284,\n",
       "  285,\n",
       "  287,\n",
       "  288,\n",
       "  290,\n",
       "  291,\n",
       "  293,\n",
       "  295,\n",
       "  297,\n",
       "  298,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  309,\n",
       "  310,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  315,\n",
       "  316,\n",
       "  317,\n",
       "  319,\n",
       "  320,\n",
       "  321,\n",
       "  322,\n",
       "  324,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  331,\n",
       "  332,\n",
       "  335,\n",
       "  337,\n",
       "  338,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  343,\n",
       "  344,\n",
       "  346,\n",
       "  350,\n",
       "  351,\n",
       "  352,\n",
       "  353,\n",
       "  356,\n",
       "  357,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  364,\n",
       "  365,\n",
       "  366,\n",
       "  367,\n",
       "  368,\n",
       "  369,\n",
       "  371,\n",
       "  372,\n",
       "  373,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  378,\n",
       "  381,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  386,\n",
       "  387,\n",
       "  389,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  394,\n",
       "  395,\n",
       "  396,\n",
       "  397,\n",
       "  398,\n",
       "  399,\n",
       "  400,\n",
       "  402,\n",
       "  403,\n",
       "  404,\n",
       "  405,\n",
       "  406,\n",
       "  407,\n",
       "  408,\n",
       "  409,\n",
       "  410,\n",
       "  411,\n",
       "  412,\n",
       "  413,\n",
       "  417,\n",
       "  418,\n",
       "  419,\n",
       "  420,\n",
       "  421,\n",
       "  422,\n",
       "  423,\n",
       "  424,\n",
       "  425,\n",
       "  426,\n",
       "  427,\n",
       "  428,\n",
       "  429,\n",
       "  430,\n",
       "  431,\n",
       "  432,\n",
       "  433,\n",
       "  434,\n",
       "  435,\n",
       "  436,\n",
       "  437,\n",
       "  439,\n",
       "  440,\n",
       "  441,\n",
       "  442,\n",
       "  444,\n",
       "  445,\n",
       "  446,\n",
       "  447,\n",
       "  448,\n",
       "  449,\n",
       "  450,\n",
       "  451,\n",
       "  452,\n",
       "  453,\n",
       "  456,\n",
       "  457,\n",
       "  458,\n",
       "  459,\n",
       "  461,\n",
       "  463,\n",
       "  464,\n",
       "  465,\n",
       "  466,\n",
       "  467,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  472,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  478,\n",
       "  479,\n",
       "  480,\n",
       "  481,\n",
       "  482,\n",
       "  483,\n",
       "  484,\n",
       "  485,\n",
       "  487,\n",
       "  488,\n",
       "  489,\n",
       "  490,\n",
       "  491,\n",
       "  492,\n",
       "  493,\n",
       "  495,\n",
       "  496,\n",
       "  497,\n",
       "  498,\n",
       "  499,\n",
       "  500,\n",
       "  501,\n",
       "  503,\n",
       "  504,\n",
       "  506,\n",
       "  507,\n",
       "  509,\n",
       "  510,\n",
       "  511,\n",
       "  512,\n",
       "  513,\n",
       "  514,\n",
       "  515,\n",
       "  517,\n",
       "  518,\n",
       "  521,\n",
       "  522,\n",
       "  523,\n",
       "  525,\n",
       "  526,\n",
       "  527,\n",
       "  528,\n",
       "  529,\n",
       "  530,\n",
       "  531,\n",
       "  533,\n",
       "  534,\n",
       "  536,\n",
       "  537,\n",
       "  539,\n",
       "  541,\n",
       "  542,\n",
       "  544,\n",
       "  545,\n",
       "  546,\n",
       "  547,\n",
       "  549,\n",
       "  550,\n",
       "  551,\n",
       "  553,\n",
       "  555,\n",
       "  556,\n",
       "  557,\n",
       "  558,\n",
       "  560,\n",
       "  561,\n",
       "  562,\n",
       "  563,\n",
       "  564,\n",
       "  565,\n",
       "  566,\n",
       "  567,\n",
       "  568,\n",
       "  569,\n",
       "  571,\n",
       "  573,\n",
       "  574,\n",
       "  575,\n",
       "  576,\n",
       "  577,\n",
       "  578,\n",
       "  584,\n",
       "  586,\n",
       "  587,\n",
       "  588,\n",
       "  589,\n",
       "  590,\n",
       "  591,\n",
       "  592,\n",
       "  593,\n",
       "  594,\n",
       "  595,\n",
       "  597,\n",
       "  598,\n",
       "  600,\n",
       "  601,\n",
       "  602,\n",
       "  603,\n",
       "  605,\n",
       "  606,\n",
       "  607,\n",
       "  608,\n",
       "  610,\n",
       "  611,\n",
       "  612,\n",
       "  613,\n",
       "  616,\n",
       "  617,\n",
       "  618,\n",
       "  619,\n",
       "  620,\n",
       "  621,\n",
       "  622,\n",
       "  623,\n",
       "  624,\n",
       "  625,\n",
       "  626,\n",
       "  627,\n",
       "  629,\n",
       "  630,\n",
       "  631,\n",
       "  632,\n",
       "  633,\n",
       "  634,\n",
       "  635,\n",
       "  636,\n",
       "  637,\n",
       "  638,\n",
       "  639,\n",
       "  640,\n",
       "  641,\n",
       "  642,\n",
       "  643,\n",
       "  644,\n",
       "  645,\n",
       "  646,\n",
       "  647,\n",
       "  648,\n",
       "  649,\n",
       "  650,\n",
       "  651,\n",
       "  652,\n",
       "  653,\n",
       "  654,\n",
       "  656,\n",
       "  657,\n",
       "  658,\n",
       "  659,\n",
       "  667,\n",
       "  668,\n",
       "  669,\n",
       "  670,\n",
       "  671,\n",
       "  672,\n",
       "  675,\n",
       "  676,\n",
       "  677,\n",
       "  678,\n",
       "  679,\n",
       "  680,\n",
       "  681,\n",
       "  682,\n",
       "  683,\n",
       "  684,\n",
       "  685,\n",
       "  686,\n",
       "  687,\n",
       "  689,\n",
       "  691,\n",
       "  692,\n",
       "  693,\n",
       "  694,\n",
       "  695,\n",
       "  696,\n",
       "  698,\n",
       "  699,\n",
       "  700,\n",
       "  701,\n",
       "  704,\n",
       "  706,\n",
       "  707,\n",
       "  708,\n",
       "  709,\n",
       "  710,\n",
       "  711,\n",
       "  712,\n",
       "  713,\n",
       "  714,\n",
       "  715,\n",
       "  716,\n",
       "  717],\n",
       " 'val_cls': [354,\n",
       "  345,\n",
       "  538,\n",
       "  283,\n",
       "  271,\n",
       "  477,\n",
       "  219,\n",
       "  655,\n",
       "  82,\n",
       "  508,\n",
       "  270,\n",
       "  334,\n",
       "  333,\n",
       "  416,\n",
       "  494,\n",
       "  53,\n",
       "  261,\n",
       "  516,\n",
       "  233,\n",
       "  604,\n",
       "  697,\n",
       "  253,\n",
       "  254,\n",
       "  690,\n",
       "  308,\n",
       "  296,\n",
       "  502,\n",
       "  596,\n",
       "  554,\n",
       "  120,\n",
       "  162,\n",
       "  349,\n",
       "  524,\n",
       "  323,\n",
       "  370,\n",
       "  87,\n",
       "  42,\n",
       "  628,\n",
       "  540,\n",
       "  17,\n",
       "  468,\n",
       "  111,\n",
       "  336,\n",
       "  76,\n",
       "  286,\n",
       "  570,\n",
       "  289,\n",
       "  64,\n",
       "  393,\n",
       "  705,\n",
       "  294,\n",
       "  703,\n",
       "  105,\n",
       "  235,\n",
       "  688,\n",
       "  123,\n",
       "  51,\n",
       "  106,\n",
       "  29,\n",
       "  543,\n",
       "  3,\n",
       "  462,\n",
       "  155,\n",
       "  115,\n",
       "  519]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = np.load('sun_cs_split.npy', allow_pickle=True).item()\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_set+val_set+test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loc = []\n",
    "val_loc = []\n",
    "test_loc = []\n",
    "\n",
    "for i, label in enumerate(class_labels):\n",
    "    if label in sd['train_cls']:\n",
    "        train_loc.append(i)\n",
    "    elif label in sd['val_cls']:\n",
    "        val_loc.append(i)\n",
    "    elif label in sd['test_cls']:\n",
    "        test_loc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
